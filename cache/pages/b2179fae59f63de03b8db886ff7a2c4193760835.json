{
  "url": "https://arxiv.org/html/2506.19030v1",
  "title": "WiLLM: An Open Wireless LLM Communication System",
  "text": "WiLLM: An Open Wireless LLM Communication System Abstract. The rapid evolution of Large Language Models (LLMs) threatens to overwhelm the existing wireless infrastructure, which calls for architectural innovations and frameworks to support the surging mobile LLM services. This paper proposes WiLLM, the first open-source wireless communication system specifically designed for LLM services, consisting of three progressive innovations. Firstly, we establish a novel paradigm by deploying LLMs in core networks (CNs) with abundant GPUs to enable distributed LLM inference services, strategically positioning LLM inference at the convergence point of the backbone bandwidth and the edges of the cellular network. Secondly, we propose an innovative extension to the conventional network slicing architecture, redefining its design with a “Tree-Branch-Fruit” framework. Its specialized adaptation for LLM services enables telecom operators to monetize these services through slice subscriptions while retaining infrastructure ownership. Finally, to operationalize this architectural vision, we present WiLLM, which systematically addresses critical limitations in existing solutions through novel key capabilities previously unattainable: (1) enhanced slice orchestration, extending existing primary slicing to implement a dual-layer slicing architecture and achieving coordinated multi-UE-multi-slice scheduling mechanisms that provide finer-grained resource allocation for LLM services; (2) universal UE compatibility through application-layer tunneling mechanisms, enabling legacy devices without native slicing capabilities to utilize LLM slice services without hardware upgrades; (3) dual-mode scheduling and cross-layer APIs, supporting flexible deployment from CNs to servers. Built on OpenAirInterface, WiLLM extends this established framework with innovations specific to LLM services, lowering the barrier for adoption by researchers without wireless expertise. Furthermore, we release the first LLM wireless communication dataset with 1,649,996 records and synchronized 58-dimensional metrics, along with two relevant benchmarks. A small but quintessential case study of smart glasses demonstrates practical viability in resource-constrained devices and human-machine interaction scenarios. WiLLM aims to build an open platform and ecosystem for cross-layer optimization and AI-telecom convergence. The code, datasets, hardwares and videos are available at https://openwillm.github.io. 1. Introduction The convergence of artificial intelligence and wireless communications represents one of the most significant technological intersections of the current decade. As computational capabilities and algorithmic sophistication continue to advance, LLMs have emerged as transformative tools with far-reaching implications across diverse application domains. The integration of these models into wireless communication systems has catalyzed a paradigm shift, enabling advanced intelligent services ranging from real-time multilingual translation to context-aware augmented reality applications (Bariah et al., 2024). As this integration accelerates, telecommunication infrastructure faces unprecedented challenges in supporting the computational demands of these resource-intensive models. Current deployments predominantly rely on either edge computing paradigms or centralized cloud processing approaches, each presenting significant limitations. Edge deployment minimizes transmission latency but suffers from constrained computational capacity and thermal limitations in user equipment (UE), while cloud-based solutions introduce unpredictable internet latency that severely impacts quality-of-experience (QoE) for interactive LLM services (Zheng et al., 2024). Moreover, the exponential growth in concurrent LLM service requests threatens to overwhelm both communication channels and computational resources, creating critical bottlenecks in service provisioning. Recent implementations across several institutions in China, including deployments of Deepseek at multiple universities (Engineer, 2025), demonstrate the feasibility of local LLM deployments at the network edge (Boateng et al., 2024). While these edge deployments represent a promising step toward LLM integration within telecommunications infrastructure, they still encounter resource limitations and scalability constraints inherent to edge computing. These implementations nonetheless validate the technical viability of localized LLM services and establish a foundation for our proposed migration of LLM computational resources to the core network, where greater processing capacity and more efficient resource allocation can be leveraged. This transition from edge to core network deployment represents a natural evolution in the LLM service architecture, addressing the scalability limitations of edge deployments while maintaining the latency advantages over cloud-based solutions (Chaoub and Elkotob, 2025). The current network architecture exhibits three fundamental drawbacks hindering effective LLM service integration: (1) the absence of dedicated open testbeds for LLM-specific communication scenarios, (2) the inherent conflict between centralized computation paradigms and distributed network architectures, and (3) the lack of viable business models for telecom operators in LLM service provisioning. Existing network slicing architectures provide potential foundations for addressing these challenges through resource isolation and service customization. However, conventional slicing methodologies primarily focus on traditional communication services and lack the specialized mechanisms required for computationally intensive LLM workloads (Dehkordi et al., 2023). Furthermore, the absence of standardized APIs and resource management frameworks inhibits the development of cross-layer optimization strategies essential for efficient LLM service delivery. Another critical limitation is the high usability barrier of current systems. Existing platforms require specialized wireless expertise and native slicing support on user equipment, restricting access primarily to communication specialists (Zheng et al., 2024). This complexity explains why testbeds are often used only by their developer communities, significantly limiting cross-disciplinary research and broader adoption for LLM service experimentation. Moreover, the field lacks comprehensive empirical datasets capturing cross-layer performance metrics, standardized benchmarking methodologies for systematic comparison, and representative case studies demonstrating viability in resource-constrained environments. This empirical deficit perpetuates the disconnect between algorithmic innovation and operational deployment, hampering the development of generalizable principles for wireless LLM communication systems. Motivated by the above system and networking challenges, we present WiLLM, the world’s first open-source wireless communication system specifically designed for mobile LLM services. Building upon the solid foundation provided by OpenAirInterface’s modular architecture, WiLLM strategically extends and enhances this established framework with specialized components for LLM service integration, creating a system that maintains compatibility with existing infrastructure while introducing transformative capabilities for AI-driven communications research. The work unifies the following progressive contributions: 1.1. Paradigm Novel Network Paradigm for LLM Services (Section 3). WiLLM establishes a novel paradigm by deploying LLMs in core networks (CNs) with GPU infrastructure, enabling distributed LLM inference services strategically positioned at the convergence point between high-bandwidth backbone connections and cellular network edges. This architectural configuration optimizes computational-communication tradeoffs while facilitating operator monetization through subscription-based network slice allocation. 1.2. Architecture “Tree-Branch-Fruit” Slicing Architecture (Section 3.3). We propose a multi-layered slicing architecture wherein the “tree” represents foundational network infrastructure, the “branches” correspond to conventional communication service slices, and the “fruits” denote specialized LLM service slices. This architecture establishes a “slice-as-LLM-service” paradigm while maintaining compatibility with existing slicing mechanisms, achieving coordinated scheduling across multiple users and slices through cross-layer resource optimization. 1.3. System The Wireless Communication System Specialized for LLM Service (Section 4). Based on OpenAirInterface, WiLLM implements five pivotal innovations: dynamic slice compatibility, universal UE compatibility, dual-mode resource scheduling, cross-layer API framework, and flexible deployment support. This integrated solution addresses critical limitations in existing wireless infrastructure while preserving backward compatibility. 1.4. Dataset The World’s First LLM Wireless Communication Dataset and Benchmarks (Section 5). We introduce the first comprehensive LLM communication dataset with 1,649,996 records, each containing 58 communication metrics synchronized across UE-gNB-CN interfaces. This enables holistic cross-layer analysis of LLM communication patterns. In addition, we present two metrics, LAREI and LSEQ, as benchmarks that offer a standardized methodology for wireless LLM service evaluation. 1.5. Case Study Smart Glasses Case Study (Section 6). The practical utility of WiLLM is validated through a smart glasses application that implements gesture-triggered queries and scene interpretation. Based on the principle of user-perceived continuity in human-computer interaction, we establish a response latency target of approximately 2 seconds, achieving optimal slicing through offline statistical analysis and online learning methodologies. 2. Related Work and Comparison 2.1. Wireless Communication for LLM The convergence of LLMs with wireless systems has precipitated prolific theoretical advancements characterized by a critical implementation deficit. Despite many approaches being proposed, the field confronts a fundamental disjunction between algorithmic innovation and operational realization. Architectural paradigms manifest in three configurations: 1. Cloud-edge frameworks (Chen et al., 2024b) (Wu et al., 2020) (Dong et al., 2024) establish a hierarchical computational distribution by allocating processing tasks between the cloud and edge devices. This approach combines the high computational power of the cloud with the low latency characteristics of the edge. For example, NetGPT (Chen et al., 2024b) relies on cloud-edge collaboration in personalized generative services. However, the dynamic nature of wireless channels limits its adaptability. Reference (Wu et al., 2020) explores the potential of cloud-edge computing, while (Dong et al., 2024) highlights the challenges of implementing edge AI generated from cloud-based LLMs. 2. Edge computing deployment (Cai et al., 2024) (Nelson and Toloui, 2023) (Tang et al., 2023) runs LLMs directly on edge servers or devices, enhancing performance through quantization techniques. For instance, Edge-LLM (Cai et al., 2024) optimizes edge adaptability using unified compression and adaptive layer voting, while (Nelson and Toloui, 2023) demonstrates hardware-supported edge deployment cases. Nevertheless, the limited capacity of edge devices remains a bottleneck, as further validated in (Tang et al., 2023). 3. Distributed architectures (Xue et al., 2024) (Mitra et al., 2024) decompose LLM computational tasks across multiple nodes to fully utilize distributed resources. For example, WDMoE (Xue et al., 2024) proposes a wireless distributed framework based on mixture-of-experts, though its validation in congested scenarios remains insufficient. Resource optimization methodologies span cross-modal approaches (JPPO (You et al., 2024)) integrating prompt compression with power optimization; adaptive partitioning strategies (Chen et al., 2024a) reconfiguring computational boundaries under network fluctuations; and collaborative frameworks (He et al., 2024) optimizing offloading decisions across distributed resources. Service integration architectures encompass specialized slicing methodologies (LLM-Slice (Liu et al., 2024)), intelligent orchestration approaches (Dandoush et al., 2024), and long-context integration strategies (Xu et al., 2025; Zhang et al., 2025). Bottlenecks and our solutions: The field faces three bottlenecks: theory-centric validation lacking real-world relevance, insufficient cross-layer integration, and unproven business viability. WiLLM addresses these through an empirical platform bridging theory and implementation. Unlike conventional edge server strategies that incur coordination inefficiencies, we deploy LLMs on GPU-equipped infrastructure at the backhaul-RAN nexus, enhancing computational capacity, resource optimization, and infrastructure integration. 2.2. Related Systems and Comparisons In this section, we evaluate prominent open-source systems for their capabilities across a range of technical features essential for modern wireless networks, including OAI, srsRAN, Open5GS, FlexRIC, and Janus. While these systems contribute significantly to wireless network research and development, they exhibit limitations in fully supporting the comprehensive demands of next-generation networks. OAI provides a complete 4G/5G protocol stack implementation, spanning from the physical layer to the network layer. Its modular design supports academic research and prototyping (Nikaein et al., 2014). srsRAN is a lightweight and highly customizable 4G/5G software suite (Gomez-Miguelez et al., 2016), offering flexibility in scheduling and QoS management. Open5GS implements comprehensive 5G core network functions, including AMF, SMF, and UPF components (Barbosa et al., 2024), establishing a solid foundation for network integration. FlexRIC is a programmable RAN SDK focused on 5G multi-tenancy and low-latency optimization (Schmidt et al., 2021). Janus is a programmable RAN platform developed by Microsoft, based on the O-RAN architecture, supporting dynamic service models (Foukas et al., 2023). While these systems offer essential assistance in certain aspects of wireless networking, they exhibit inadequate support for general technical features like UE compatibility, slice flexibility, and specialized support for LLM communications, etc. Detailed objective metric comparisons are presented in Table 2 and Table 1 in the Appendix. 2.2.1. Research Gaps and Positioning of WiLLM While existing open-source communication platforms provide valuable research infrastructure, comprehensive analysis reveals significant operability impediments that restrict their adoption beyond specialized research communities. As quantified in Table 1 and 2, current systems demonstrate substantial limitations in critical usability dimensions. The requirement for native slicing support at the UE level presents a particularly problematic constraint, effectively excluding standard commercial devices without specialized protocol modifications (Saboorian and Xiang, 2017; Andrade and Wickboldt, 2025). This limitation fundamentally contradicts the purpose of experimental testbeds, which should facilitate algorithm validation across diverse implementation scenarios rather than constraining experimental configurations to narrow protocol-specific deployments. Furthermore, these resulted in an undesirable ecosystem fragmentation where testbeds remain utilized primarily by their own development communities, significantly limiting cross-disciplinary innovation. WiLLM aims to bridge the technological gap between wireless communication and LLM systems by extending the OAI architecture to build the first open-source wireless communication system designed specifically for LLM services. 3. Paradigm LLMs as transformative technologies in wireless communications call for fundamental network architecture reconceptualization. Despite edge computing’s partial success in LLM deployment, its device-centric approach inherently limits scalability and optimization. We propose a novel core network paradigm that positions LLM resources at the nexus of high-capacity backhaul and wireless access networks, enabling comprehensive computational-communication resource integration that transcends traditional edge computing constraints. 3.1. Deployment Paradigm for LLM Services Current LLM service deployment architectures exhibit fundamental architectural limitations that constrain their performance envelopes. As illustrated in Figure 2, traditional cloud-based configurations necessitate traversal of multiple network boundaries: from UE through gNB and CN to remote LLM servers via public internet infrastructure. This architectural paradigm introduces non-deterministic network latency due to Internet Gateway traversal, unpredictable congestion during peak utilization periods, and critically, a decoupling of computational and communication resource management planes that prevents cross-layer optimization. Our proposed paradigm, depicted in the right section of Figure 2, implements a strategic reconfiguration wherein GPU resources are directly integrated within the core network infrastructure. This implementation positions LLM computational capabilities precisely at the convergence point between high-bandwidth backbone connections and cellular network edges. Technically, this architecture establishes a single-track service flow where UE requests traverse a deterministic path (UEgNBCN with integrated GPU) rather than extending through variable internet routes. The implementation incorporates dedicated GPU modules within the core network nodes, connected via high-speed backplane interconnects to the CN’s packet processing infrastructure. This architectural positioning enables packet processing, slice scheduling, and LLM inference to occur within the same administrative domain, eliminating inter-domain traversal overhead that characterizes cloud deployments while providing computational density unattainable in resource-constrained edge implementations. The technical implementation comprises three principal architectural components: - (1) Deterministic Service Path Integration: As shown in Figure 2, our implementation establishes a direct service flow from UE through gNB to the CN-GPU integrated infrastructure. This configuration eliminates the indeterministic routing and potential congestion points inherent in public internet traversal, enabling guaranteed service-level agreement enforcement through contiguous administrative control of the entire transmission path. - (2) Hierarchical Slice-Based Resource Orchestration: The implementation leverages the slice management mechanisms detailed in Section 3.3 to establish fine-grained coordination between communication and computational resources. Rather than treating these as separate resource domains (as in conventional implementations), our architecture implements a unified resource allocation framework where slice policies govern both radio resource allocation at the gNB and computational resource distribution at the CN-GPU nexus. - (3) End-to-End Service Flow Management: The architecture implements a comprehensive flow control mechanism that extends from UE request initiation through transmission scheduling, computational resource allocation, and response delivery. This coordinated approach enables advanced optimization techniques such as predictive resource allocation, where the system anticipates computational requirements based on request characteristics and proactively configures both network and computational resources accordingly. 3.2. Transcending Edge Computing Limitations The core network deployment paradigm for LLM services introduces fundamental architectural, operational, and infrastructural enhancements that transcend edge computing’s intrinsic limitations. The hierarchical “Tree-Branch-Fruit” slicing framework (Section 3.3) enables differentiated, SLA-governed LLM orchestration, surpassing edge computing’s localized resource allocation. The cross-layer optimization framework (Sections 4.2) synergistically coordinates resources across network strata, realizing dynamic adaptation unattainable through edge computing’s device-centricity. Strategic LLM resource placement at the backhaul-RAN confluence forges a computational-communication symbiosis, transcending edge deployments’ latency-processing tradeoffs. Empirical insights from the WiLLM dataset (Sections 5) corroborate the core network paradigm’s transformative potential, illuminating performance benefits and optimization opportunities eclipsing edge computing. This paradigm establishes the foundation for the “Tree-Branch-Fruit” slicing architecture, facilitating a technical environment where both communication resources and computational capabilities can be allocated through unified slice policies. The implementation enables an evolutionary deployment path that preserves investment in existing infrastructure while advancing sophisticated LLM service delivery models. 3.3. “Tree-Branch-Fruit” Slicing Architecture Building upon our core network deployment paradigm, we propose a novel “Tree-Branch-Fruit” slicing architecture that transforms conventional network slicing approaches into a comprehensive service provisioning platform. This multi-tier architecture, illustrated in Figure. 3, establishes a hierarchical framework that maintains backward compatibility with existing slicing mechanisms while introducing specialized LLM service slices. In this architecture: - • Tree (gNB): Represents the foundational radio access network infrastructure, serving as the common entry point for all network traffic and the root of the slicing hierarchy. - • Branch Slices: Correspond to traditional communication service slices defined in 5G standards, including enhanced Mobile Broadband (eMBB), Ultra-Reliable Low-Latency Communication (URLLC), and massive Machine Type Communication (mMTC). These branch slices are not the focus and implementations of this work. These branches maintain backward compatibility with existing network functions. - • Fruit Slices: Denote specialized LLM service slices that extend from branch slices, each configured for specific application domains and computational requirements. Figure. 3 presents illustrative examples of potential fruit slice configurations, including various LLM service use cases with different model sizes tailored to specific application requirements. The examples illustrated in Figure. 4 demonstrate how different application domains might be served by appropriately sized language models, with computationally intensive applications connected to branches supporting higher bandwidth and more powerful models, while lightweight IoT applications utilize smaller, more efficient models. These examples are not prescriptive implementations but rather illustrative use cases demonstrating the flexibility of the proposed architecture. This architecture establishes a “slice-as-a-LLM-service” paradigm that facilitates efficient multi-user and multi-slice coordinated scheduling through cross-layer resource optimization. The hierarchical structure enables: - • Differentiated Service Provisioning: Telecom operators can provide LLM services with varying performance guarantees and computational capacities tailored to specific application requirements and price points. - • Resource Isolation: The architecture enforces strict isolation between service slices, preventing performance degradation in one service from affecting others and enabling guaranteed quality-of-service levels. - • Domain-Specific Optimization: Each fruit slice can be independently optimized for its specific application domain, with tailored model selection, inference parameters, and resource allocation strategies. - • Modular Service Evolution: New LLM services can be deployed as additional fruit slices without disrupting existing services, facilitating incremental innovation. Our architecture achieves forward compatibility via application-layer tunneling that transcends conventional slicing constraints. This method encapsulates LLM traffic within standard application protocols, enabling infrastructure compatibility while maintaining architectural autonomy. The approach provides telecommunications operators with implementation flexibility independent of underlying radio network slice capabilities. This strategic decoupling of service implementation from network infrastructure allows fruit slices to evolve asynchronously from hardware upgrade cycles or standardization timelines. Such architectural independence ensures operational resilience across heterogeneous networks, enabling deployment of novel LLM capabilities unfettered by the limitations of conventional slicing frameworks. The monetary value icons associated with different fruit slices in Figure. 3 illustrate the differentiated pricing potential of this architecture, with higher-resource slices commanding premium pricing while lightweight services remain cost-effective for mass deployment. This economic framework creates sustainable incentives for network operators to invest in LLM-capable infrastructure. The “Tree-Branch-Fruit” architecture represents an advancement over conventional slicing approaches by introducing application-specific service customization while maintaining backward compatibility with existing network functions. This novel paradigm establishes the foundation for our comprehensive WiLLM implementation, which will be detailed in subsequent sections. 4. The Proposed System This section presents the comprehensive design and implementation of WiLLM, our novel wireless communication system specifically optimized for LLM service delivery. Building upon the “Tree-Branch-Fruit” slicing architecture described in Section 3, we have constructed a complete system implementation that extends the OpenAirInterface framework with specialized components for LLM service provisioning. Figure. 5 illustrates the system architecture, encompassing UE, gNB, core network, and edge server components with their associated interconnections and functional modules. 4.1. System Architecture Overview WiLLM adopts an innovative vertical integration architecture design, achieving end-to-end coordination from user applications to core networks through a hierarchical management framework. This architecture, centered on layered slice management, organically integrates four key subsystems: the CN subsystem built on the Open5GS framework, with enhanced edge computing capabilities through a dedicated Edge Server Bridge; the gNB subsystem that implements enhanced “Tree-Branch-Fruit” slice management mechanisms based on OpenAirInterface; the UE subsystem that integrates configuration management, slice control, and performance measurement function modules; and the edge server subsystem that carries various LLM deployments and executes corresponding slice policies. These subsystems are not simply stacked together but are tightly coupled through a hierarchical slice management framework, enabling precise scheduling and collaborative optimization of cross-layer resources, thereby ensuring the efficiency of the LLM communication system. 4.2. Implementation Framework WiLLM extends OpenAirInterface with strategic innovations that balance implementation efficiency with transformative functionality. This approach leverages established communication foundations while introducing specialized components that fundamentally transform system capabilities: 4.2.1. Dynamic Slice Compatibility As illustrated in Figure. 5, our implementation extends conventional network slicing capabilities with LLM-specific service slices while maintaining backward compatibility. The Slice Manager of gNB encompasses both Branch Slice-UE Mapping and Fruit Slice-UE Mapping components, with bidirectional data flows (indicated by the UE Update and UE State Report pathways) enabling dynamic reassignment of resources in response to changing service demands. The implementation employs a virtualization layer that abstracts underlying slice implementation details, while the Branch Slice Policy Executor and Fruit Slice Policy Executor enforce service-specific policies at the gNB level. As shown in the left section of Figure. 5, these policy executors interact directly with the PRB Manager, creating a decision hierarchy that translates high-level service policies into physical resource allocations. 4.2.2. Universal UE Compatibility To address the limitations of current UE implementations, which often lack native slicing capabilities, WiLLM incorporates a middleware-based slice access mechanism through the Slice Manager of UE component. The data flow illustrated in Figure. 5 demonstrates how this component interfaces with both the Configuration Manager and Hot Start Module, enabling UEs without native slicing support to access specialized LLM services through application-layer tunneling techniques that encapsulate service traffic within standard data streams. This compatibility layer effectively bypasses the limitations of current community implementations of primary slicing, which remain incomplete and inconsistently supported across device ecosystems, thereby expanding the addressable user base for LLM services. 4.2.3. Multi-UE Multi-Slice Scheduling Capability WiLLM implements a comprehensive multi-UE-multi-slice coordinated scheduling mechanism that operates through a two-phase process. The Scheduler module in Figure. 5 forms the nexus of this coordination, receiving inputs from multiple sources including the Buffer Manager (which provides Buffer Status information), HARQ Manager (which signals Retransmission Requirements), and the Slice Allocation of UE component. The multi-UE-multi-slice coordination operates through a two-phase process: - • A global allocation phase distributes available physical resource blocks across active slices according to their relative priorities and resource guarantees. - • An intra-slice scheduling phase allocates resources to individual UEs within each slice based on service-specific metrics. This hierarchical approach ensures fair and efficient resource utilization while maintaining service isolation, effectively enabling legacy devices to benefit from slice-specific performance guarantees without hardware modifications. 4.2.4. Dual-Mode Resource Scheduling WiLLM implements complementary “separated” and “embedded” resource scheduling methodologies to accommodate diverse operational requirements and infrastructure constraints: - • Embedded Scheduling Mode: The embedded approach implements slice-aware resource allocation directly within the scheduler pipeline, as formalized in Algorithm 1. Figure. 5 illustrates how this approach integrates with the Resource Grid and Spectrum Usage Tracking components to maintain awareness of physical layer constraints while implementing policy decisions. - • Separated Scheduling Mode: The separated approach decouples slice-specific policy decisions from core scheduling logic, employing an external decision engine that solves a global optimization problem and subject to resource constraints and slice isolation requirements. The data flow in Figure. 5 shows how the Resource Update pathway enables this external engine to maintain synchronization with the core scheduling system. The interaction between the Uplink/Downlink Allocation Request pathways and the PUCCH Allocator modules for both uplink and downlink control channels (as depicted in Figure. 5) demonstrates how the system coordinates the allocation of scarce control channel resources across multiple UEs and slices. 4.2.5. Cross-Layer API Framework WiLLM introduces a comprehensive API architecture (detailed in Figure. 16) that facilitates vertical integration between application requirements and network-level resource allocation. As shown in Figure. 5, this framework enables multiple feedback pathways: - (1) Performance Feedback Loop: The UE State Report, Configuration/Feedback/Buffer, and UE Update connections establish a closed-loop feedback system that continuously monitors service performance and adapts resource allocation accordingly. The bidirectional nature of these connections, clearly depicted in Figure. 5, enables adaptive behavior at multiple timescales. - (2) Service-Specific Optimization: The LLM Service ID mechanism enables adaptation of network parameters based on computational characteristics of different LLM implementations. Figure. 5 illustrates how this information flows from the Edge Server Subsystem through the Slice Manager to influence allocation decisions. - (3) Resource Utilization Monitoring: The Resource Usage and Slice Allocation connections provide visibility into consumption patterns, establishing a cross-layer information flow that informs both immediate scheduling decisions and longer-term policy refinements. 4.2.6. Deployment Flexibility The system supports flexible LLM deployment configurations, with the Edge Server Large Language Model Deployment component hosting multiple LLM variants with different parameter sizes as shown in Figure. 5, and the CN-Edge Server Bridge facilitating seamless integration between computational resources and network infrastructure through standardized file and network interfaces. 4.3. The Database Module A distinctive feature of WiLLM is its integrated data collection module (shown in the upper section of Figure. 5), which continuously refines resource allocation strategies based on operational metrics. This module creates a meta-feedback loop that transcends individual communication sessions, collecting performance data from UE’s Performance, gNB Measurement, and Server Measurement components to inform the evolution of the Customized QoS Scheduler and Model components. The system incorporates a comprehensive Database component (illustrated in the right section of Figure. 5) that persistently stores operational metrics, enabling longitudinal analysis of system performance. This data repository serves as both an analytical resource for offline optimization and a training corpus for online learning algorithms. 4.4. System Validation Infrastructure To validate practical performance, we deployed a fully functional testbed (Figure.14 in Appendix) integrating a complete wireless communication chain with LLM service deployment. Following the logical architecture shown in Figure. 5, the core computing infrastructure employs an Intel Core i9-14900KF processor as gNB host, USRP B210 for RF frontend, and NVIDIA RTX 4090 GPU for LLM inference, supporting multi-user, multi-slice concurrent testing scenarios. The system’s operational status can be monitored through a custom GUI (Figure. 15 in Appendix). This configuration achieves complete system integration from radio access to core network, providing an ideal environment for evaluating WiLLM in practical deployments. 5. The WiLLM Dataset We present the first comprehensive LLM communication dataset with synchronized metrics, enabling reproducible research and systematic evaluation. Appendix F details components, acquisition, synchronization, and error descriptions. 5.1. Dataset Metrics Overview Our dataset contains 1,649,996 records with 58 metrics spanning the LLM service delivery chain. It covers four scenarios: static UE and gNB (290,653 records), dynamic UE and static gNB (363,906 records), static UE and dynamic gNB (430,369 records), and dynamic UE and gNB (565,068 records). “Dynamic” indicates dynamically allocated network slices, while “static” indicates invariant parameters throughout measurements. The dataset includes 22 metrics at the user equipment layer, 25 at the wireless access network layer, and 18 at the edge server layer. Figures 17 and 18 confirm stable base station power and noise levels during data collection. We implemented NTP-based distributed synchronization, calibrating all devices through a common server for microsecond-level sampling precision. By recording timestamps at both the UE and server endpoints and using latency compensation algorithms, we maintained synchronization errors within 1.0 milliseconds. 5.2. Metric Architecture The dataset provides synchronized metrics across three architectural layers: UE Metrics (Appendix Table 4) capture end-user experience through latency, timing, resolution, modalities, and payload characteristics; gNB Metrics (Appendix Table 6) document wireless conditions via radio parameters (MCS, CQI, BLER), resource allocation, transmission performance, and slice configuration; and CN with Edge Server Metrics (Appendix Table 5) measure computational aspects through inference timing, token processing, model loading, and response generation. The dataset’s value lies in its temporal synchronization, enabling precise correlation between user experience, network conditions, and computational performance. This facilitates advanced research: developing ML models for scheduling, implementing data-driven allocation, creating cross-layer analytics, and validating theoretical models. This corpus establishes a foundation for reproducible research in wireless systems supporting LLM services. 5.3. Preliminary Findings and Conclusions This section presents preliminary findings derived from our dataset, with particular focus on communication directionality characteristics and the impact of network slicing on performance metrics. 5.3.1. Uplink vs. Downlink Characteristic Analysis Finding 1: Our dataset reveals distinct performance profiles for uplink and downlink communication scenarios. In the uplink case (UE image request LLM inference text response), as visualized in Figure. 6, we observe that inference time constitutes a substantial proportion of the total processing latency (74-87% across resolution groups). The relative contribution of uplink transmission time marginally increases (11-25%) with the rise in resolution. Finding 2: In contrast, the downlink scenarios (text request LLM text response image response), depicted in Figure. 7, demonstrate markedly different characteristics. Downlink transmission time dominates the overall latency budget (81-86%), with inference time contributing a significantly smaller proportion (12-17%). Conclusions: These directional performance characteristics validate WiLLM’s “Tree-Branch-Fruit” slicing architecture and LLM deployment paradigm in several critical ways: - (1) In the uplink scenario, the largest delay comes from inference time, followed by uplink transmission time. This finding supports our strategy of deploying LLMs with GPUs in the CN. This is achieved by reducing the inference time through distributed LLM processing at the CN and minimizing uplink transmission delays by staying close to users, thereby avoiding the need to go through the public Internet. - (2) The pronounced asymmetry between uplink and downlink transmission characteristics empirically validates our “Fruit Slice” architectural paradigm, confirming that effective monetization of LLM services requires direction-specific slice configurations that independently optimize bandwidth and computation intensive workloads, a capability that is not achievable through conventional slicing approaches. - (3) The pronounced resource requirement asymmetry between uplink and downlink scenarios provides compelling empirical justification for direction-specific scheduling mechanisms. These findings validate the architectural necessity of dual-mode scheduling capabilities, confirming that efficient LLM service delivery requires dynamic, direction-aware resource provisioning rather than single-direction allocation policies. This increased flexibility in provisioning is a key enabler of the slice-based monetization framework. These insights reveal"
}